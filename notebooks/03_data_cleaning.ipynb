{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99374bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1d6b85",
   "metadata": {},
   "source": [
    "Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616adbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DIR = \"../data/processed\"\n",
    "OUTPUT_DIR = \"../data/outputs\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac380b",
   "metadata": {},
   "source": [
    "Raster Visualization Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9f9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_raster(path, title=None, cmap=\"viridis\", vmin=None, vmax=None):\n",
    "    with rasterio.open(path) as src:\n",
    "        img = src.read(1)\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        plt.title(title or os.path.basename(path))\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c4a50",
   "metadata": {},
   "source": [
    "Raster to Dataframe Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ec91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_dataframe(path, band_name):\n",
    "    with rasterio.open(path) as src:\n",
    "        data = src.read(1).flatten()\n",
    "    return pd.DataFrame({band_name: data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9197c8",
   "metadata": {},
   "source": [
    "Collect Processed Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64aa40d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 raster files.\n"
     ]
    }
   ],
   "source": [
    "raster_files = glob.glob(os.path.join(PROCESSED_DIR, \"*.tif\"))\n",
    "print(f\"Found {len(raster_files)} raster files.\")\n",
    "\n",
    "from collections import defaultdict\n",
    "fire_groups = defaultdict(dict)\n",
    "for f in raster_files:\n",
    "    fname = os.path.basename(f)\n",
    "    fire, layer = fname.split(\"_\")[0], fname.split(\"_\")[1].split(\".\")[0]\n",
    "    fire_groups[fire][layer] = f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb257d8a",
   "metadata": {},
   "source": [
    "Build Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e84dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fire: Bootleg\n",
      "Processing fire: Camp\n",
      "Processing fire: Creek\n",
      "Processing fire: CZU\n",
      "Processing fire: Dixie\n",
      " Warning: Missing NDVI for Dixie, filling with NaN.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['EVI', 'NBR', 'VCI', 'SPI', 'dNBR']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_13088\\3376072881.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     20\u001b[39m     fire_df = pd.concat(dfs, axis=\u001b[32m1\u001b[39m)\n\u001b[32m     21\u001b[39m     fire_df[\u001b[33m\"fire\"\u001b[39m] = fire\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Drop rows where everything is NaN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     fire_df = fire_df.dropna(how=\u001b[33m\"all\"\u001b[39m, subset=expected_layers)\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m     all_data.append(fire_df)\n\u001b[32m     27\u001b[39m \n",
      "\u001b[32mc:\\Users\\John Waugh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6666\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6667\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6668\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6669\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6670\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6671\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6672\u001b[39m \n\u001b[32m   6673\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['EVI', 'NBR', 'VCI', 'SPI', 'dNBR']"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "for fire, layers in fire_groups.items():\n",
    "    print(f\"Processing fire: {fire}\")\n",
    "\n",
    "# Required layers\n",
    "expected_layers = [\"NDVI\", \"EVI\", \"NBR\", \"VCI\", \"SPI\", \"dNBR\"]\n",
    "available_layers = {k: v for k, v in layers.items() if k in expected_layers}\n",
    "\n",
    "# Load available rasters\n",
    "dfs = []\n",
    "for lyr in expected_layers:\n",
    "    if lyr in available_layers:\n",
    "        df = raster_to_dataframe(available_layers[lyr], lyr)\n",
    "        dfs.append(df)\n",
    "    else:\n",
    "        print(f\" Warning: Missing {lyr} for {fire}, filling with NaN.\")\n",
    "        # Fill with NaN if layer missing\n",
    "        dfs.append(pd.DataFrame({lyr: [np.nan] * len(dfs[0]) if dfs else [np.nan]}))\n",
    "\n",
    "    fire_df = pd.concat(dfs, axis=1)\n",
    "    fire_df[\"fire\"] = fire\n",
    "\n",
    "    # Drop rows where everything is NaN\n",
    "    fire_df = fire_df.dropna(how=\"all\", subset=expected_layers)\n",
    "\n",
    "    all_data.append(fire_df)\n",
    "\n",
    "dataset = pd.concat(all_data, ignore_index=True)\n",
    "print(f\"Final dataset shape: {dataset.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
