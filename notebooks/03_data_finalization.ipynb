{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa03ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad188f51",
   "metadata": {},
   "source": [
    "Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153c0d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_dir = \"../data/processed\"\n",
    "output_data_dir = \"../data/outputs\"\n",
    "\n",
    "os.makedirs(output_data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462d9af",
   "metadata": {},
   "source": [
    "Load/Align Rasters Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b342b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_align_rasters(file_list, reference_raster=None):\n",
    "    \"\"\"\n",
    "    Loads a list of rasters and aligns them to a common resolution/extent.\n",
    "    If reference_raster is provided, aligns all to that raster.\n",
    "    Returns an xarray.Dataset with all rasters stacked as variables.\n",
    "    \"\"\"\n",
    "    rasters = []\n",
    "    names = []\n",
    "\n",
    "    for file in file_list:\n",
    "        arr = rxr.open_rasterio(file, masked=True).squeeze()\n",
    "        names.append(os.path.splitext(os.path.basename(file))[0])\n",
    "\n",
    "        # Reproject/align if reference is given\n",
    "        if reference_raster is not None:\n",
    "            arr = arr.rio.reproject_match(reference_raster)\n",
    "\n",
    "        rasters.append(arr)\n",
    "\n",
    "    # Stack into dataset\n",
    "    ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c96769",
   "metadata": {},
   "source": [
    "Severity Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83893d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_severity(dnbr):\n",
    "    if dnbr < 0.1:\n",
    "        return \"Unburned\"\n",
    "    elif dnbr < 0.27:\n",
    "        return \"Low\"\n",
    "    elif dnbr < 0.44:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"High\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4668478",
   "metadata": {},
   "source": [
    "Process All Fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76454d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Bootleg fire ...\n",
      "Skipping Bootleg — no dNBR available.\n",
      "Processing Caldor fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Caldor dataset with 5517951 pixels → ../data/outputs\\Caldor_dataset.parquet\n",
      "Processing Camp fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Camp dataset with 5609430 pixels → ../data/outputs\\Camp_dataset.parquet\n",
      "Processing Carr fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Carr dataset with 5680136 pixels → ../data/outputs\\Carr_dataset.parquet\n",
      "Processing Creek fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Creek dataset with 5427398 pixels → ../data/outputs\\Creek_dataset.parquet\n",
      "Processing Dixie fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Dixie dataset with 5625635 pixels → ../data/outputs\\Dixie_dataset.parquet\n",
      "Processing Glass fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Glass dataset with 3832992 pixels → ../data/outputs\\Glass_dataset.parquet\n",
      "Processing Thomas fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Thomas dataset with 4458250 pixels → ../data/outputs\\Thomas_dataset.parquet\n",
      "Processing Troublesome fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Troublesome dataset with 5576320 pixels → ../data/outputs\\Troublesome_dataset.parquet\n",
      "Processing Woolsey fire ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John Waugh\\AppData\\Local\\Temp\\ipykernel_11424\\1609434101.py:21: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n",
      "  ds = xr.merge([rasters[i].to_dataset(name=names[i]) for i in range(len(rasters))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Woolsey dataset with 2091670 pixels → ../data/outputs\\Woolsey_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "all_fire_dfs = []\n",
    "\n",
    "# Detect fires based on available files\n",
    "fires = sorted(set(os.path.basename(f).split(\"_\")[0] for f in glob(os.path.join(processed_data_dir, \"*.tif\"))))\n",
    "\n",
    "for fire_name in fires:\n",
    "    print(f\"Processing {fire_name} fire ...\")\n",
    "\n",
    "    fire_files = glob(os.path.join(processed_data_dir, f\"{fire_name}_*.tif\"))\n",
    "    dnbr_path = os.path.join(processed_data_dir, f\"{fire_name}_dNBR.tif\")\n",
    "\n",
    "    if not os.path.exists(dnbr_path):\n",
    "        print(f\"Skipping {fire_name} — no dNBR available.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        reference = rxr.open_rasterio(dnbr_path, masked=True).squeeze()\n",
    "        fire_ds = load_and_align_rasters(fire_files, reference_raster=reference)\n",
    "\n",
    "        # Mask no-data areas based on dNBR\n",
    "        fire_ds = fire_ds.where(~np.isnan(fire_ds[f\"{fire_name}_dNBR\"]), drop=True)\n",
    "\n",
    "        # Convert to dataframe\n",
    "        df = fire_ds.to_dataframe().reset_index()\n",
    "        df = df.dropna()\n",
    "        df[\"fire_name\"] = fire_name\n",
    "        df[\"severity\"] = df[f\"{fire_name}_dNBR\"].apply(classify_severity)\n",
    "\n",
    "        # Save individual file\n",
    "        fire_output = os.path.join(output_data_dir, f\"{fire_name}_dataset.parquet\")\n",
    "        df.to_parquet(fire_output, index=False)\n",
    "        print(f\"Saved {fire_name} dataset with {len(df)} pixels → {fire_output}\")\n",
    "\n",
    "        all_fire_dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fire_name}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a482a49e",
   "metadata": {},
   "source": [
    "Combine Fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0afaa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 fire datasets to combine.\n",
      "\n",
      "[1/10] Processed 'Caldor' — 5,517,951 rows (Total: 5,517,951)\n",
      "[2/10] Processed 'Camp' — 5,609,430 rows (Total: 11,127,381)\n",
      "[3/10] Processed 'Carr' — 5,680,136 rows (Total: 16,807,517)\n",
      "[4/10] Processed 'combined' — 42,265,444 rows (Total: 59,072,961)\n",
      "[5/10] Processed 'Creek' — 5,427,398 rows (Total: 64,500,359)\n",
      "[6/10] Processed 'Dixie' — 5,625,635 rows (Total: 70,125,994)\n",
      "[7/10] Processed 'Glass' — 3,832,992 rows (Total: 73,958,986)\n",
      "[8/10] Processed 'Thomas' — 4,458,250 rows (Total: 78,417,236)\n",
      "[9/10] Processed 'Troublesome' — 5,576,320 rows (Total: 83,993,556)\n",
      "[10/10] Processed 'Woolsey' — 2,091,670 rows (Total: 86,085,226)\n"
     ]
    }
   ],
   "source": [
    "fire_datasets = list(Path(output_data_dir).glob('*_dataset.parquet'))\n",
    "\n",
    "output_file = Path(\"combined_dataset.parquet\")\n",
    "\n",
    "if output_file.exists():\n",
    "    output_file.unlink()\n",
    "\n",
    "writer = None\n",
    "total_rows = 0\n",
    "\n",
    "print(f\"Found {len(fire_datasets)} fire datasets to combine.\\n\")\n",
    "\n",
    "for i, file in enumerate(fire_datasets, start=1):\n",
    "    fire_name = file.stem.replace('_dataset', '')\n",
    "    \n",
    "    df = pd.read_parquet(file)\n",
    "\n",
    "    df.columns = [re.sub(f\"^{fire_name}_\", \"\", c) for c in df.columns]\n",
    "    df = df.rename(columns={\n",
    "        'x': 'longitude',\n",
    "        'y': 'latitude',\n",
    "        'veg_indices': 'NDVI'\n",
    "    })\n",
    "\n",
    "    if 'fire_name' not in df.columns:\n",
    "        df['fire_name'] = fire_name\n",
    "    else:\n",
    "        df['fire_name'] = df['fire_name'].fillna(fire_name)\n",
    "\n",
    "    expected_cols = ['latitude', 'longitude', 'dNBR', 'SPI', 'VCI', 'NDVI', 'severity', 'fire_name']\n",
    "    available_cols = [c for c in expected_cols if c in df.columns]\n",
    "    df = df[available_cols]\n",
    "\n",
    "    for col in ['dNBR', 'SPI', 'VCI', 'NDVI', 'severity']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce', downcast='float')\n",
    "\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    if writer is None:\n",
    "        writer = pq.ParquetWriter(output_file, table.schema)\n",
    "    writer.write_table(table)\n",
    "\n",
    "    total_rows += len(df)\n",
    "    print(f\"[{i}/{len(fire_datasets)}] Processed '{fire_name}' — {len(df):,} rows (Total: {total_rows:,})\")\n",
    "\n",
    "if writer:\n",
    "    writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
